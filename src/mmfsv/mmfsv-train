#!/usr/bin/env python3
import os
import argparse
import torch
import pytorch_lightning as pl
from pytorch_lightning.loggers import TensorBoardLogger
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning import seed_everything

import ray
from ray import tune
from ray.tune import CLIReporter
from ray.tune.search import Repeater
from ray.tune.schedulers import ASHAScheduler
from ray.tune.search.hyperopt import HyperOptSearch
# from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback
# from hyperopt import hp

from mmfsv.net import IDENet

def main():

    parser = argparse.ArgumentParser(description="F-SV Training Only (Ray Tune or Normal Training)")
    parser.add_argument('-D', '--data_dir', type=str, required=True,
                        help="Path to the data directory")
    parser.add_argument('-bs', '--batch_size', type=int, default=16,
                        help="Batch size for training (default: 16)")
    parser.add_argument('-GPU', '--GPU_index', type=str, default="0",
                        help="GPU index used for training (default: 0)")
    parser.add_argument('--use_tune', action='store_true',
                        help="where use Ray Tune.")
    args = parser.parse_args()

    my_label = "7+11channel_predict_5fold"
    data_dir = args.data_dir
    bs = args.batch_size
    num_cuda = args.GPU_index

    seed_everything(2024)

    os.environ["CUDA_VISIBLE_DEVICES"] = num_cuda


    logger = TensorBoardLogger(
        save_dir=os.path.join(data_dir, "channel_predict"),
        name=my_label
    )

    checkpoint_callback = ModelCheckpoint(
        dirpath="./checkpoints_predict/" + my_label,
        filename='{epoch:02d}-{validation_f1:.2f}-{train_mean:.2f}',
        monitor="validation_f1",
        verbose=False,
        save_last=None,
        save_top_k=1,
        mode="max",
        auto_insert_metric_name=True
    )

    print("\n<=============== F-SV: Training ===============>")

    def main_train():
        config = {
            "batch_size": bs,
            "beta1": 0.9,
            "beta2": 0.999,
            "lr": 7.187267009530772e-06,
            "weight_decay": 0.0011614665567890423,
            "model_name": "resnet50",
            "KFold": 5,
            "KFold_num": 0,
        }
        model = IDENet(data_dir, config)

        trainer = pl.Trainer(
            max_epochs=30,
            accelerator="gpu",
            devices=num_gpus,
            check_val_every_n_epoch=1,
            logger=logger,
            callbacks=[checkpoint_callback],
        )
        trainer.fit(model)

    def train_tune(config, checkpoint_dir=None, num_epochs=200, num_gpus=1):
        model = IDENet(data_dir, config)
        checkpoint_callback_tune = ModelCheckpoint(
            dirpath="./checkpoints_predict/" + my_label + "_tune",
            filename='{epoch:02d}-{validation_f1:.2f}-{validation_mean:.2f}',
            monitor="validation_f1",
            verbose=False,
            save_last=None,
            save_top_k=1,
            mode="max",
            auto_insert_metric_name=True
        )
        trainer = pl.Trainer(
            max_epochs=num_epochs,
            accelerator="gpu",
            devices=num_gpus,
            check_val_every_n_epoch=1,
            logger=logger,
            callbacks=[checkpoint_callback_tune],
        )
        trainer.fit(model)

    class MyStopper(tune.Stopper):
        def __init__(self, metric, value, epoch=1):
            self._metric = metric
            self._value = value
            self._epoch = epoch

        def __call__(self, trial_id, result):
            return (result["training_iteration"] > self._epoch) and (result[self._metric] < self._value)

        def stop_all(self):
            return False

    def gan_tune(num_samples=-1, num_epochs=30, gpus_per_trial=1):
        config = {
            "batch_size": bs,
            "lr": tune.loguniform(1e-7, 1e-5),
            "weight_decay": tune.uniform(0, 0.001),
            "beta1": 0.9,
            "beta2": 0.999,
            "model_name": "ViT-B/32",
            "use_kfold": False,
        }

        bayesopt = HyperOptSearch(metric="validation_f1", mode="max")
        re_search_alg = Repeater(bayesopt, repeat=1)

        scheduler = ASHAScheduler(
            max_t=num_epochs,
            grace_period=1,
            reduction_factor=2,
        )

        reporter = CLIReporter(
            metric_columns=['train_loss', "train_f1", 'validation_loss', "validation_f1"]
        )

        analysis = tune.run(
            tune.with_parameters(
                train_tune,
                num_epochs=num_epochs,
            ),
            local_dir=os.path.join(data_dir, "ray_logs"),
            resources_per_trial={"cpu": 1, "gpu": 1},
            config=config,
            num_samples=num_samples,
            metric='validation_f1',
            mode='max',
            scheduler=scheduler,
            progress_reporter=reporter,
            resume=False,
            search_alg=re_search_alg,
            max_failures=-1,
            name="5fold_" + num_cuda
        )

    if args.use_tune:
        print(">> Use Ray Tune...")
        ray.init()
        gan_tune(num_samples=10, num_epochs=30, gpus_per_trial=1)
    else:
        print(">> Oridinary training...")
        main_train()


if __name__ == "__main__":
    main()
